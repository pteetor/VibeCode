Chat with local LLM models directly in your browser using this interactive chat application.
The LLM models are running in LM Studio server, which has an API compatible with OpenAI.
The server is at network address 192.168.1.10, port 1234.
No authentication is required.
Select from the multiple models available via the API.
The app displays real-time streaming responses, tracks API usage metrics,
and measures response duration to help you monitor your interactions.
